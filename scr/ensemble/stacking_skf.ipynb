{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スタッキング\n",
    "・GBDT 2~3個：決定木の深さが「浅い」「普通」「深い」モデル\n",
    "\n",
    "・Random Forest 1~2個：決定木の深さが「浅い」「深い」モデル\n",
    "\n",
    "・Neural Net 1~2個：層の数が「少ない」「多い」モデル\n",
    "\n",
    "・Linier 1個"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scr.models.gbdt import Model1_CatBoost_1, Model1_CatBoost_2, Model1_CatBoost_3, Model1_XGBoost_1, Model1_XGBoost_2, Model1_XGBoost_3, Model1_LightGBM_1, Model1_LightGBM_2, Model1_LightGBM_3\n",
    "from scr.models.random_forest import Model1_RandomForest_1, Model1_RandomForest_2, Model1_RandomForest_3\n",
    "from scr.models.nn import Model1_NN_1, Model1_NN_2, Model1_NN_all_1, Model1_NN_all_2, Model1_TabNet_1, Model1_TabNet_2\n",
    "from scr.models.linear import Model1_Logistic_1, Model1_Logistic_2, Model1_Logistic_3, Model1_Logistic_4, Model2_Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/feature_engineered/null_cat/train_scaled_for_not_gbdt.csv')\n",
    "df_test = pd.read_csv('data/feature_engineered/null_cat/test_scaled_for_not_gbdt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [\n",
    "    'Age', \n",
    "    'DurationOfPitch', \n",
    "    'NumberOfPersonVisiting',\n",
    "    'NumberOfFollowups', \n",
    "    'NumberOfTrips', \n",
    "    'MonthlyIncome', \n",
    "    #'ProdTaken',\n",
    "    'Motivation', \n",
    "    'EconomicPower', \n",
    "    'TripEasier', \n",
    "    'SalesPerformance',\n",
    "    'LivingCost', \n",
    "    'EconomicStability', \n",
    "    'NumberOfTrips_log', \n",
    "    'TravelCost',\n",
    "    'EconomicSegment', \n",
    "    'PackageMatch', \n",
    "    'Monetary', \n",
    "    #'ContractRate_FM',\n",
    "    #'ContractRate_G1',\n",
    "    #'ContractRate_G2', \n",
    "    #'ContractRate_G3',\n",
    "    #'ContractRate_G4',\n",
    "    #'ContractRate_G5', \n",
    "    #'ContractRate_G6',\n",
    "    'TypeofContact_No',\n",
    "    'TypeofContact_Self Enquiry',\n",
    "    'CityTier_2',\n",
    "    'CityTier_3',\n",
    "    'Occupation_Salaried',\n",
    "    'Occupation_Small Business',\n",
    "    'Gender_male', \n",
    "    'ProductPitched_Deluxe', \n",
    "    'ProductPitched_King',\n",
    "    'ProductPitched_Standard',\n",
    "    'ProductPitched_Super Deluxe',\n",
    "    'PreferredPropertyStar_4',\n",
    "    'PreferredPropertyStar_5', \n",
    "    'Passport_1',\n",
    "    'PitchSatisfactionScore_2', \n",
    "    'PitchSatisfactionScore_3',\n",
    "    'PitchSatisfactionScore_4',\n",
    "    'PitchSatisfactionScore_5',\n",
    "    'Designation_Executive',\n",
    "    'Designation_Manager',\n",
    "    'Designation_Senior Manager', \n",
    "    'Designation_VP',\n",
    "    'Marry_Married',\n",
    "    'Marry_Single', \n",
    "    'Car_No Car', \n",
    "    'Child_1_child', \n",
    "    'Child_2_child',\n",
    "    'Child_3_child',\n",
    "    'AgeGroup_20s',\n",
    "    'AgeGroup_30s',\n",
    "    'AgeGroup_40s',\n",
    "    'AgeGroup_50s', \n",
    "    'AgeGroup_60s', \n",
    "    'TypeofContactNULL_1',\n",
    "    'Child01_1',\n",
    "    'IsFamily_1',\n",
    "    'FreaqencySeg_1',\n",
    "    'FreaqencySeg_2',\n",
    "    'MonetarySeg_2',\n",
    "    'MonetarySeg_3', \n",
    "    'MonetarySeg_4', \n",
    "    'AgeNull', \n",
    "    'DurationOfPitchNull',\n",
    "    'NumberOfTripsNull', \n",
    "    'MonthlyIncomeNull'\n",
    "]\n",
    "\n",
    "X = df_train[feature]\n",
    "y = df_train['ProdTaken']\n",
    "\n",
    "df_test = df_test[feature]\n",
    "\n",
    "num_features = len(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スタッキング\n",
    "def predict_cv(model, X, y, df_test):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(skf.split(X, y)):\n",
    "        tr_x, va_x = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(df_test)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "\n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricke\\anaconda3\\envs\\neuralnet\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# 1層目のモデル\n",
    "models_gbdt = [\n",
    "    Model1_CatBoost_1(),\n",
    "    Model1_CatBoost_2(),\n",
    "    Model1_CatBoost_3(),\n",
    "    Model1_XGBoost_1(),\n",
    "    Model1_XGBoost_2(),\n",
    "    Model1_XGBoost_3(),\n",
    "    Model1_LightGBM_1(),\n",
    "    Model1_LightGBM_2(),\n",
    "    Model1_LightGBM_3(),\n",
    "    Model1_RandomForest_1(),\n",
    "    Model1_RandomForest_2(),\n",
    "    Model1_RandomForest_3()\n",
    "]\n",
    "\n",
    "models_nn = [\n",
    "    Model1_NN_1(input_shape=num_features),\n",
    "    Model1_NN_2(input_shape=num_features),\n",
    "    Model1_NN_all_1(input_shape=num_features),\n",
    "    Model1_NN_all_2(input_shape=num_features),\n",
    "    Model1_TabNet_1(input_dim=num_features),\n",
    "    Model1_TabNet_2(input_dim=num_features),\n",
    "    Model1_Logistic_1(),\n",
    "    Model1_Logistic_2(),\n",
    "    Model1_Logistic_3(),\n",
    "    Model1_Logistic_4()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6015970\tbest: 0.6015970 (0)\ttotal: 2.07ms\tremaining: 143ms\n",
      "69:\ttest: 0.8174415\tbest: 0.8220736 (43)\ttotal: 135ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8220735786\n",
      "bestIteration = 43\n",
      "\n",
      "Shrink model to first 44 iterations.\n",
      "0:\ttest: 0.5922993\tbest: 0.5922993 (0)\ttotal: 2.53ms\tremaining: 175ms\n",
      "69:\ttest: 0.8067057\tbest: 0.8295485 (22)\ttotal: 154ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.829548495\n",
      "bestIteration = 22\n",
      "\n",
      "Shrink model to first 23 iterations.\n",
      "0:\ttest: 0.5802432\tbest: 0.5802432 (0)\ttotal: 3.47ms\tremaining: 239ms\n",
      "69:\ttest: 0.7766311\tbest: 0.7876258 (22)\ttotal: 192ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.787625841\n",
      "bestIteration = 22\n",
      "\n",
      "Shrink model to first 23 iterations.\n",
      "0:\ttest: 0.5700578\tbest: 0.5700578 (0)\ttotal: 2.64ms\tremaining: 182ms\n",
      "69:\ttest: 0.7837305\tbest: 0.7940170 (31)\ttotal: 142ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7940169643\n",
      "bestIteration = 31\n",
      "\n",
      "Shrink model to first 32 iterations.\n",
      "0:\ttest: 0.5882909\tbest: 0.5882909 (0)\ttotal: 2.78ms\tremaining: 192ms\n",
      "69:\ttest: 0.7733860\tbest: 0.7959697 (27)\ttotal: 138ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7959697308\n",
      "bestIteration = 27\n",
      "\n",
      "Shrink model to first 28 iterations.\n",
      "0:\ttest: 0.5995485\tbest: 0.5995485 (0)\ttotal: 3.67ms\tremaining: 253ms\n",
      "69:\ttest: 0.8276254\tbest: 0.8290134 (58)\ttotal: 262ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8290133779\n",
      "bestIteration = 58\n",
      "\n",
      "Shrink model to first 59 iterations.\n",
      "0:\ttest: 0.5926672\tbest: 0.5926672 (0)\ttotal: 5.9ms\tremaining: 407ms\n",
      "69:\ttest: 0.8272575\tbest: 0.8316054 (47)\ttotal: 250ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8316053512\n",
      "bestIteration = 47\n",
      "\n",
      "Shrink model to first 48 iterations.\n",
      "0:\ttest: 0.5653530\tbest: 0.5653530 (0)\ttotal: 2.76ms\tremaining: 190ms\n",
      "69:\ttest: 0.7842701\tbest: 0.7873392 (41)\ttotal: 240ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.787339168\n",
      "bestIteration = 41\n",
      "\n",
      "Shrink model to first 42 iterations.\n",
      "0:\ttest: 0.5671827\tbest: 0.5671827 (0)\ttotal: 3.14ms\tremaining: 217ms\n",
      "69:\ttest: 0.8032580\tbest: 0.8154163 (17)\ttotal: 229ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8154162662\n",
      "bestIteration = 17\n",
      "\n",
      "Shrink model to first 18 iterations.\n",
      "0:\ttest: 0.6040336\tbest: 0.6040336 (0)\ttotal: 2.7ms\tremaining: 186ms\n",
      "69:\ttest: 0.7782001\tbest: 0.7814770 (41)\ttotal: 227ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7814769771\n",
      "bestIteration = 41\n",
      "\n",
      "Shrink model to first 42 iterations.\n",
      "0:\ttest: 0.5995485\tbest: 0.5995485 (0)\ttotal: 6.95ms\tremaining: 480ms\n",
      "69:\ttest: 0.8090803\tbest: 0.8090803 (69)\ttotal: 363ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8090802676\n",
      "bestIteration = 69\n",
      "\n",
      "0:\ttest: 0.5926672\tbest: 0.5926672 (0)\ttotal: 3.17ms\tremaining: 219ms\n",
      "69:\ttest: 0.8277759\tbest: 0.8277759 (69)\ttotal: 328ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8277759197\n",
      "bestIteration = 69\n",
      "\n",
      "0:\ttest: 0.5653530\tbest: 0.5653530 (0)\ttotal: 6.24ms\tremaining: 431ms\n",
      "69:\ttest: 0.7777441\tbest: 0.7944217 (14)\ttotal: 364ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7944216792\n",
      "bestIteration = 14\n",
      "\n",
      "Shrink model to first 15 iterations.\n",
      "0:\ttest: 0.5671827\tbest: 0.5671827 (0)\ttotal: 4.97ms\tremaining: 343ms\n",
      "69:\ttest: 0.7950119\tbest: 0.7953154 (64)\ttotal: 373ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7953154247\n",
      "bestIteration = 64\n",
      "\n",
      "Shrink model to first 65 iterations.\n",
      "0:\ttest: 0.6040336\tbest: 0.6040336 (0)\ttotal: 8.28ms\tremaining: 571ms\n",
      "69:\ttest: 0.7615790\tbest: 0.7616128 (64)\ttotal: 379ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7616127834\n",
      "bestIteration = 64\n",
      "\n",
      "Shrink model to first 65 iterations.\n",
      "[0]\ttrain-auc:0.80987\teval-auc:0.79555\n",
      "[69]\ttrain-auc:0.90411\teval-auc:0.84398\n",
      "[0]\ttrain-auc:0.78844\teval-auc:0.78033\n",
      "[69]\ttrain-auc:0.90544\teval-auc:0.85035\n",
      "[0]\ttrain-auc:0.79806\teval-auc:0.74556\n",
      "[69]\ttrain-auc:0.90990\teval-auc:0.81818\n",
      "[0]\ttrain-auc:0.76372\teval-auc:0.75730\n",
      "[69]\ttrain-auc:0.91197\teval-auc:0.82666\n",
      "[0]\ttrain-auc:0.79132\teval-auc:0.75847\n",
      "[69]\ttrain-auc:0.91583\teval-auc:0.80665\n",
      "[0]\ttrain-auc:0.84992\teval-auc:0.76405\n",
      "[69]\ttrain-auc:0.97480\teval-auc:0.84097\n",
      "[0]\ttrain-auc:0.81742\teval-auc:0.78584\n",
      "[69]\ttrain-auc:0.97467\teval-auc:0.84368\n",
      "[0]\ttrain-auc:0.83919\teval-auc:0.74124\n",
      "[69]\ttrain-auc:0.97529\teval-auc:0.80835\n",
      "[0]\ttrain-auc:0.82016\teval-auc:0.71404\n",
      "[69]\ttrain-auc:0.97807\teval-auc:0.81727\n",
      "[0]\ttrain-auc:0.82652\teval-auc:0.73628\n",
      "[69]\ttrain-auc:0.98107\teval-auc:0.77443\n",
      "[0]\ttrain-auc:0.87772\teval-auc:0.74737\n",
      "[69]\ttrain-auc:0.99784\teval-auc:0.83181\n",
      "[0]\ttrain-auc:0.85365\teval-auc:0.80139\n",
      "[69]\ttrain-auc:0.99759\teval-auc:0.84234\n",
      "[0]\ttrain-auc:0.86923\teval-auc:0.74350\n",
      "[69]\ttrain-auc:0.99788\teval-auc:0.81263\n",
      "[0]\ttrain-auc:0.85455\teval-auc:0.75606\n",
      "[69]\ttrain-auc:0.99820\teval-auc:0.80724\n",
      "[0]\ttrain-auc:0.86914\teval-auc:0.73697\n",
      "[69]\ttrain-auc:0.99914\teval-auc:0.77134\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1868\n",
      "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 57\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
      "[LightGBM] [Info] Start training from score -1.796785\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 58\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
      "[LightGBM] [Info] Start training from score -1.796785\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m pred_test_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models_gbdt:\n\u001b[1;32m----> 4\u001b[0m     pred_train, pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     pred_train_list\u001b[38;5;241m.\u001b[39mappend(pred_train)\n\u001b[0;32m      6\u001b[0m     pred_test_list\u001b[38;5;241m.\u001b[39mappend(pred_test)\n",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m, in \u001b[0;36mpredict_cv\u001b[1;34m(model, X, y, df_test)\u001b[0m\n\u001b[0;32m     10\u001b[0m tr_x, va_x \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[tr_idx], X\u001b[38;5;241m.\u001b[39miloc[va_idx]\n\u001b[0;32m     11\u001b[0m tr_y, va_y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[tr_idx], y\u001b[38;5;241m.\u001b[39miloc[va_idx]\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(va_x)\n\u001b[0;32m     14\u001b[0m preds\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[1;32mc:\\Users\\ricke\\Python\\Competition\\SIGNATE\\SIGNATE Summer Cup 2024\\scr\\models\\gbdt.py:215\u001b[0m, in \u001b[0;36mModel1_LightGBM_1.fit\u001b[1;34m(self, tr_x, tr_y, va_x, va_y)\u001b[0m\n\u001b[0;32m    213\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(tr_x, label\u001b[38;5;241m=\u001b[39mtr_y)\n\u001b[0;32m    214\u001b[0m dval \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(va_x, label\u001b[38;5;241m=\u001b[39mva_y, reference\u001b[38;5;241m=\u001b[39mdtrain)\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7000\u001b[39;49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricke\\anaconda3\\envs\\neuralnet\\lib\\site-packages\\lightgbm\\engine.py:313\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_sets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m--> 313\u001b[0m         evaluation_result_list\u001b[38;5;241m.\u001b[39mextend(\u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    314\u001b[0m     evaluation_result_list\u001b[38;5;241m.\u001b[39mextend(booster\u001b[38;5;241m.\u001b[39meval_valid(feval))\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ricke\\anaconda3\\envs\\neuralnet\\lib\\site-packages\\lightgbm\\basic.py:4389\u001b[0m, in \u001b[0;36mBooster.eval_train\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   4357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_train\u001b[39m(\n\u001b[0;32m   4358\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4359\u001b[0m     feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4360\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_LGBM_BoosterEvalMethodResultType]:\n\u001b[0;32m   4361\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate for training data.\u001b[39;00m\n\u001b[0;32m   4362\u001b[0m \n\u001b[0;32m   4363\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4387\u001b[0m \u001b[38;5;124;03m        List with (train_dataset_name, eval_name, eval_result, is_higher_better) tuples.\u001b[39;00m\n\u001b[0;32m   4388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inner_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_data_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricke\\anaconda3\\envs\\neuralnet\\lib\\site-packages\\lightgbm\\basic.py:5166\u001b[0m, in \u001b[0;36mBooster.__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   5163\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_inner_eval, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   5164\u001b[0m tmp_out_len \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   5165\u001b[0m _safe_call(\n\u001b[1;32m-> 5166\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterGetEval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_out_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOINTER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_double\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5172\u001b[0m )\n\u001b[0;32m   5173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tmp_out_len\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_inner_eval:\n\u001b[0;32m   5174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length of eval results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_train_list = []\n",
    "pred_test_list = []\n",
    "for model in models_gbdt:\n",
    "    pred_train, pred_test = predict_cv(model, X, y, df_test)\n",
    "    pred_train_list.append(pred_train)\n",
    "    pred_test_list.append(pred_test)\n",
    "for model in models_nn:\n",
    "    pred_train, pred_test = predict_cv(model, X, y, df_test)\n",
    "    pred_train_list.append(pred_train)\n",
    "    pred_test_list.append(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1層目のモデル\n",
    "\n",
    "# model_1a = Model1_CatBoost_1()\n",
    "# pred_train_1a, pred_test_1a = predict_cv(model_1a, X, y, df_test)\n",
    "\n",
    "# model_1b = Model1_CatBoost_2()\n",
    "# pred_train_1b, pred_test_1b = predict_cv(model_1b, X, y, df_test)\n",
    "\n",
    "# model_1c = Model1_CatBoost_3()\n",
    "# pred_train_1c, pred_test_1c = predict_cv(model_1c, X, y, df_test)\n",
    "\n",
    "# model_1d = Model1_RandomForest_1()\n",
    "# pred_train_1d, pred_test_1d = predict_cv(model_1d, X, y, df_test)\n",
    "\n",
    "# model_1e = Model1_RandomForest_2()\n",
    "# pred_train_1e, pred_test_1e = predict_cv(model_1e, X, y, df_test)\n",
    "\n",
    "# model_1f = Model1_NN_1()\n",
    "# pred_train_1f, pred_test_1f = predict_cv(model_1f, X, y, df_test)\n",
    "\n",
    "# model_1g = Model1_NN_2()\n",
    "# pred_train_1g, pred_test_1g = predict_cv(model_1g, X, y, df_test)\n",
    "\n",
    "# model_1h = Model1_Logistic_1()\n",
    "# pred_train_1h, pred_test_1h = predict_cv(model_1h, X, y, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for model 1: 0.5979466370415003\n",
      "AUC for model 2: 0.6462047687192675\n",
      "AUC for model 3: 0.6970506192233615\n",
      "AUC for model 4: 0.8289382014009188\n",
      "AUC for model 5: 0.8167386672979051\n",
      "AUC for model 6: 0.8129727563240405\n",
      "AUC for model 7: 0.8118291971077802\n",
      "AUC for model 8: 0.8178822265141652\n",
      "AUC for model 9: 0.8184790561551124\n",
      "AUC for model 10: 0.812139548521073\n",
      "AUC for model 11: 0.8198650458903153\n",
      "AUC for model 12: 0.8213593055660164\n",
      "AUC for model 13: 0.8465377828468134\n",
      "AUC for model 14: 0.8344855227622419\n",
      "AUC for model 15: 0.9146940466327376\n",
      "AUC for model 16: 0.927937276062794\n",
      "AUC for model 17: 0.7842455804344783\n",
      "AUC for model 18: 0.7682915675873422\n",
      "AUC for model 19: 0.8300316605515446\n",
      "AUC for model 20: 0.8255885580864869\n",
      "AUC for model 21: 0.7994699480304285\n",
      "AUC for model 22: 0.739332384682426\n"
     ]
    }
   ],
   "source": [
    "# 1層目のモデルの評価\n",
    "for i, pred_train in enumerate(pred_train_list):\n",
    "    auc_score = roc_auc_score(y, pred_train)\n",
    "    print(f'AUC for model {i+1}: {auc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量として使用する列名を作成\n",
    "column_names = [f'pred_{i+1}' for i in range(len(pred_train_list))]\n",
    "\n",
    "# 予測値を特徴量としてデータフレームを作成\n",
    "train_x_2 = pd.DataFrame(\n",
    "    {f'pred_{i+1}': pred_train_list[i] for i in range(len(pred_train_list))},\n",
    "    columns=column_names\n",
    ")\n",
    "\n",
    "test_x_2 = pd.DataFrame(\n",
    "    {f'pred_{i+1}': pred_test_list[i] for i in range(len(pred_test_list))},\n",
    "    columns=column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 予測値を特徴量としてデータフレームを作成\n",
    "# train_x_2 = pd.DataFrame({\n",
    "#     'pred_1a': pred_train_1a,\n",
    "#     'pred_1b': pred_train_1b,\n",
    "#     'pred_1c': pred_train_1c,\n",
    "#     'pred_1d': pred_train_1d,\n",
    "#     'pred_1e': pred_train_1e,\n",
    "#     'pred_1f': pred_train_1f,\n",
    "#     'pred_1g': pred_train_1g,\n",
    "#     'pred_1h': pred_train_1h\n",
    "#     })\n",
    "\n",
    "# test_x_2 = pd.DataFrame({\n",
    "#     'pred_1a': pred_test_1a,\n",
    "#     'pred_1b': pred_test_1b,\n",
    "#     'pred_1c': pred_test_1c,\n",
    "#     'pred_1d': pred_test_1d,\n",
    "#     'pred_1e': pred_test_1e,\n",
    "#     'pred_1f': pred_test_1f,\n",
    "#     'pred_1g': pred_test_1g,\n",
    "#     'pred_1h': pred_test_1h,\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9182669546691916\n"
     ]
    }
   ],
   "source": [
    "# 2層目のモデル\n",
    "# pred_train_2は、2層目のモデルの学習データのクロスバリデーションでの予測値\n",
    "# pred_test_2は、2層目のモデルのテストデータの予測値\n",
    "model_2 = Model2_Logistic()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, y, test_x_2)\n",
    "print(f'AUC: {roc_auc_score(y, pred_train_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv('data/test.csv')['id'].values\n",
    "df_submit = pd.DataFrame({\n",
    "    \"id\": index,\n",
    "    \"prediction\": pred_test_2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'submission/submit_25_second_stacking.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv(path, index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
