{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スタッキング\n",
    "・GBDT 2~3個：決定木の深さが「浅い」「普通」「深い」モデル\n",
    "\n",
    "・Random Forest 1~2個：決定木の深さが「浅い」「深い」モデル\n",
    "\n",
    "・Neural Net 1~2個：層の数が「少ない」「多い」モデル\n",
    "\n",
    "・Linier 1個"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scr.util import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scr.models.gbdt import Model1_CatBoost_1, Model1_CatBoost_2, Model1_CatBoost_3, Model1_XGBoost_1, Model1_XGBoost_2, Model1_XGBoost_3, Model1_LightGBM_1, Model1_LightGBM_2, Model1_LightGBM_3\n",
    "from scr.models.random_forest import Model1_RandomForest_1, Model1_RandomForest_2, Model1_RandomForest_3\n",
    "from scr.models.nn import Model1_NN_1, Model1_NN_2, Model1_NN_all_1, Model1_NN_all_2, Model1_TabNet_1, Model1_TabNet_2\n",
    "from scr.models.linear import Model1_Logistic_1, Model1_Logistic_2, Model1_Logistic_3, Model1_Logistic_4, Model2_Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_gb = pd.read_csv('data/feature_engineered/null_representative/train_null_mean.csv')\n",
    "df_test_gb = pd.read_csv('data/feature_engineered/null_representative/test_null_mean.csv')\n",
    "combination_gb= df_train_gb.columns[44:110]\n",
    "\n",
    "df_train_nn = pd.read_csv('data/feature_engineered/null_representative/train_null_mean_scaled.csv')\n",
    "df_test_nn = pd.read_csv('data/feature_engineered/null_representative/test_null_mean_scaled.csv')\n",
    "\n",
    "y = df_train_gb['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量が多いので、落とす特徴量を選択\n",
    "drop_gb = [\n",
    "    'EconomicSegment',\n",
    "    'ContractRate_FM',\n",
    "    'ContractRate_G1',\n",
    "    'ContractRate_G2',\n",
    "    'ContractRate_G3',\n",
    "    'ContractRate_G4',\n",
    "    'ContractRate_G5',\n",
    "    'ContractRate_G6'\n",
    "]\n",
    "\n",
    "## --------------------------------------------------------------------------------------------\n",
    "## Label Encoding\n",
    "df_train_gb = mapping_columns_if_exist(df_train_gb)\n",
    "df_test_gb = mapping_columns_if_exist(df_test_gb)\n",
    "\n",
    "def handle_unknown_label(train_series, test_series):\n",
    "    unique_labels = train_series.unique()\n",
    "    label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    train_encoded = train_series.map(label_map)\n",
    "    test_encoded = test_series.map(lambda x: label_map.get(x, -1))\n",
    "    return train_encoded, test_encoded\n",
    "\n",
    "for col in combination_gb:\n",
    "    df_train_gb[col], df_test_gb[col] = handle_unknown_label(df_train_gb[col], df_test_gb[col])\n",
    "## --------------------------------------------------------------------------------------------\n",
    "\n",
    "X_gb = df_train_gb.drop(columns=drop_gb, axis=1)\n",
    "y_gb = df_train_gb['ProdTaken']\n",
    "\n",
    "df_test_gb = df_test_gb.drop(columns=drop_gb, axis=1)\n",
    "\n",
    "num_features_gb = len(df_test_gb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_nn = [\n",
    "    'EconomicSegment',\n",
    "    'ContractRate_FM',\n",
    "    'ContractRate_G1',\n",
    "    'ContractRate_G2',\n",
    "    'ContractRate_G3',\n",
    "    'ContractRate_G4',\n",
    "    'ContractRate_G5',\n",
    "    'ContractRate_G6'\n",
    "]\n",
    "\n",
    "X_nn = df_train_nn.drop(columns=drop_nn, axis=1)\n",
    "y_nn = df_train_nn['ProdTaken']\n",
    "\n",
    "df_test_nn = df_test_nn.drop(columns=drop_nn, axis=1)\n",
    "\n",
    "num_features_nn = len(df_test_nn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スタッキング\n",
    "def predict_cv(model, X, y, df_test):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(skf.split(X, y)):\n",
    "        tr_x, va_x = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        \n",
    "        # Target Encoding\n",
    "        \n",
    "        \n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(df_test)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "\n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1層目のモデル\n",
    "models_gbdt = [\n",
    "    Model1_CatBoost_1(),\n",
    "    Model1_CatBoost_2(),\n",
    "    Model1_CatBoost_3(),\n",
    "    #Model1_XGBoost_1(),\n",
    "    #Model1_XGBoost_2(),\n",
    "    #Model1_XGBoost_3(),\n",
    "    #Model1_LightGBM_1(),\n",
    "    #Model1_LightGBM_2(),\n",
    "    #Model1_LightGBM_3(),\n",
    "    #Model1_RandomForest_1(),\n",
    "    Model1_RandomForest_2(),\n",
    "    #Model1_RandomForest_3()\n",
    "]\n",
    "\n",
    "models_nn = [\n",
    "    Model1_NN_1(input_shape=num_features_nn),\n",
    "    Model1_NN_2(input_shape=num_features_nn),\n",
    "    Model1_NN_all_1(input_shape=num_features_nn),\n",
    "    Model1_NN_all_2(input_shape=num_features_nn),\n",
    "    #Model1_TabNet_1(input_dim=num_features_nn),\n",
    "    #Model1_TabNet_2(input_dim=num_features_nn),\n",
    "    Model1_Logistic_1(),\n",
    "    Model1_Logistic_2(),\n",
    "    #Model1_Logistic_3(),\n",
    "    #Model1_Logistic_4()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5795987\tbest: 0.5795987 (0)\ttotal: 2.03ms\tremaining: 14.2s\n",
      "200:\ttest: 0.8288796\tbest: 0.8288796 (200)\ttotal: 386ms\tremaining: 13.1s\n",
      "400:\ttest: 0.8345318\tbest: 0.8359365 (312)\ttotal: 811ms\tremaining: 13.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m pred_test_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models_gbdt:\n\u001b[1;32m----> 4\u001b[0m     pred_train, pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_gb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test_gb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     pred_train_list\u001b[38;5;241m.\u001b[39mappend(pred_train)\n\u001b[0;32m      6\u001b[0m     pred_test_list\u001b[38;5;241m.\u001b[39mappend(pred_test)\n",
      "Cell \u001b[1;32mIn[55], line 12\u001b[0m, in \u001b[0;36mpredict_cv\u001b[1;34m(model, X, y, df_test)\u001b[0m\n\u001b[0;32m     10\u001b[0m tr_x, va_x \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[tr_idx], X\u001b[38;5;241m.\u001b[39miloc[va_idx]\n\u001b[0;32m     11\u001b[0m tr_y, va_y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[tr_idx], y\u001b[38;5;241m.\u001b[39miloc[va_idx]\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(va_x)\n\u001b[0;32m     14\u001b[0m preds\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[1;32mc:\\Users\\ricke\\Python\\Competition\\SIGNATE\\SIGNATE Summer Cup 2024\\scr\\models\\gbdt.py:24\u001b[0m, in \u001b[0;36mModel1_CatBoost_1.fit\u001b[1;34m(self, tr_x, tr_y, va_x, va_y)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, tr_x, tr_y, va_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, va_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 24\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtr_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtr_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mva_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricke\\anaconda3\\envs\\neuralnet\\lib\\site-packages\\catboost\\core.py:5201\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5199\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5201\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5202\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5203\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ricke\\anaconda3\\envs\\neuralnet\\lib\\site-packages\\catboost\\core.py:2396\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2393\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2405\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\ricke\\anaconda3\\envs\\neuralnet\\lib\\site-packages\\catboost\\core.py:1776\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1777\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4833\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4882\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_train_list = []\n",
    "pred_test_list = []\n",
    "for model in models_gbdt:\n",
    "    pred_train, pred_test = predict_cv(model, X_gb, y_gb, df_test_gb)\n",
    "    pred_train_list.append(pred_train)\n",
    "    pred_test_list.append(pred_test)\n",
    "for model in models_nn:\n",
    "    pred_train, pred_test = predict_cv(model, X_nn, y_nn, df_test_nn)\n",
    "    pred_train_list.append(pred_train)\n",
    "    pred_test_list.append(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for model 1: 0.8087502286445948\n",
      "AUC for model 2: 0.8259819612864352\n",
      "AUC for model 3: 0.8290901828080783\n",
      "AUC for model 4: 0.8206585771312366\n",
      "AUC for model 5: 0.8435089144492625\n",
      "AUC for model 6: 0.8460125727627799\n",
      "AUC for model 7: 0.910081478173856\n",
      "AUC for model 8: 0.915961006681802\n",
      "AUC for model 9: 0.8305629229925003\n",
      "AUC for model 10: 0.8260270177213009\n"
     ]
    }
   ],
   "source": [
    "# 1層目のモデルの評価\n",
    "for i, pred_train in enumerate(pred_train_list):\n",
    "    auc_score = roc_auc_score(y, pred_train)\n",
    "    print(f'AUC for model {i+1}: {auc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量として使用する列名を作成\n",
    "column_names = [f'pred_{i+1}' for i in range(len(pred_train_list))]\n",
    "\n",
    "# 予測値を特徴量としてデータフレームを作成\n",
    "train_x_2 = pd.DataFrame(\n",
    "    {f'pred_{i+1}': pred_train_list[i] for i in range(len(pred_train_list))},\n",
    "    columns=column_names\n",
    ")\n",
    "\n",
    "test_x_2 = pd.DataFrame(\n",
    "    {f'pred_{i+1}': pred_test_list[i] for i in range(len(pred_test_list))},\n",
    "    columns=column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9141412647005026\n"
     ]
    }
   ],
   "source": [
    "# 2層目のモデル\n",
    "# pred_train_2は、2層目のモデルの学習データのクロスバリデーションでの予測値\n",
    "# pred_test_2は、2層目のモデルのテストデータの予測値\n",
    "model_2 = Model2_Logistic()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, y, test_x_2)\n",
    "print(f'AUC: {roc_auc_score(y, pred_train_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv('data/test.csv')['id'].values\n",
    "df_submit = pd.DataFrame({\n",
    "    \"id\": index,\n",
    "    \"prediction\": pred_test_2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'submission/submit_27.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv(path, index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
